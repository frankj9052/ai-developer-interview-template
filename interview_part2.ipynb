{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ff383a",
   "metadata": {},
   "source": [
    "## Question 1 ‚Äî NLP Mini Practical (Sentiment, CSV)\n",
    "\n",
    "**Scenario**  \n",
    "Your team needs to implement a minimal **sentiment analysis module**.  \n",
    "Given an English sentence, output whether the sentiment is **`positive`** or **`negative`**.\n",
    "\n",
    "---\n",
    "\n",
    "**Input**  \n",
    "CSV file **`sentiment.csv`** with the following columns:\n",
    "\n",
    "- `text` ‚Äî an English sentence  \n",
    "- `label` ‚Äî one of `positive` or `negative` (ground truth)\n",
    "\n",
    "---\n",
    "\n",
    "**What to Build**\n",
    "\n",
    "1. `load_sentiment_csv(path: str = \"./data/sentiment.csv\") -> pd.DataFrame`  \n",
    "2. `predict_sentiment(text: str) -> str` ‚Üí returns **exactly** `\"positive\"` or `\"negative\"`  \n",
    "3. `predict_sentiment_batch(texts: list[str]) -> list[str]`  \n",
    "\n",
    "---\n",
    "\n",
    "**Baseline Requirements (Rule-Based)**\n",
    "\n",
    "- Handle **case-insensitivity**.  \n",
    "- Ignore **punctuation** (reasonable tokenization is acceptable).  \n",
    "- Use **lexicon-based rules** as a starting point.  \n",
    "\n",
    "We provide a very small **sample lexicon** below.  \n",
    "üëâ You should **expand it** (add synonyms and common variants to improve accuracy).\n",
    "\n",
    "- `POSITIVE_WORDS` (sample): `{\"good\", \"great\", \"excellent\"}`  \n",
    "- `NEGATIVE_WORDS` (sample): `{\"bad\", \"terrible\", \"awful\"}`  \n",
    "- `NEGATIONS` (sample): `{\"not\", \"no\", \"never\", \"n't\"}`  \n",
    "  *(can be used for polarity flipping, e.g., ‚Äúnot good‚Äù ‚Üí negative)*  \n",
    "\n",
    "---\n",
    "\n",
    "**Optional (Stretch Goal): Transformer Calibration**\n",
    "\n",
    "- If your environment allows (e.g., internet access and `transformers` installed),  \n",
    "  you may additionally run an off-the-shelf model:  \n",
    "  ```python\n",
    "  from transformers import pipeline\n",
    "  sentiment_model = pipeline(\"sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2fedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 ‚Äî Code Skeleton\n",
    "from typing import List\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# --- SAMPLE LEXICONS (expand these) ---\n",
    "POSITIVE_WORDS = {\"good\", \"great\", \"excellent\"}       # expand\n",
    "NEGATIVE_WORDS = {\"bad\", \"terrible\", \"awful\"}         # expand\n",
    "NEGATIONS = {\"not\", \"no\", \"never\", \"n't\"}             # expand if you handle negation\n",
    "\n",
    "# --- Tokenization (you may replace with your own) ---\n",
    "TOKEN_RE = re.compile(r\"[a-z']+\")\n",
    "\n",
    "def load_sentiment_csv(path: str = \"./data/sentiment.csv\") -> pd.DataFrame:\n",
    "    \"\"\"Load sentiment.csv and return a DataFrame with columns ['text','label'].\"\"\" \n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def predict_sentiment(text: str) -> str:\n",
    "    \"\"\"Return 'positive' or 'negative'.\n",
    "    Implement a rule-based classifier using the lexicons above.\n",
    "    - Case-insensitive\n",
    "    - Ignore punctuation (e.g., via regex tokenization)\n",
    "    - (Optional) Handle negation flipping, e.g., 'not good' -> negative\n",
    "    \"\"\"\n",
    "    # TODO: implement your sentiment classifier\n",
    "    # Hints (not required): lowercase, tokenize, count pos/neg hits, apply (optional) negation flip\n",
    "    pass\n",
    "\n",
    "\n",
    "def predict_sentiment_batch(texts: List[str]) -> List[str]:\n",
    "    \"\"\"Vectorized helper that applies predict_sentiment to a list of texts.\"\"\"\n",
    "    return [predict_sentiment(t) for t in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional ‚Äî Transformer Calibration (reference solution)\n",
    "try:\n",
    "    import pandas as pd\n",
    "    from transformers import pipeline\n",
    "\n",
    "    # Á°Æ‰øù CSV Â∑≤Âä†ËΩΩ\n",
    "    if \"df\" not in globals():\n",
    "        df = load_sentiment_csv(\"./data/sentiment.csv\")\n",
    "\n",
    "    # ÊòæÂºèÊåáÂÆöÊ®°ÂûãÔºåÈÅøÂÖç warning\n",
    "    sentiment_model = pipeline(\n",
    "        task=\"sentiment-analysis\",\n",
    "        model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "        revision=\"af0f99b\"   # ‰Ω†ÁöÑÁéØÂ¢ÉÊó•ÂøóÈáåÊèêÁ§∫ÁöÑ revision\n",
    "    )\n",
    "\n",
    "    # ÊâπÈáèÊé®ÁêÜ\n",
    "    texts = df[\"text\"].tolist()\n",
    "    raw_preds = sentiment_model(texts, batch_size=16, truncation=True)\n",
    "\n",
    "    # label Áªü‰∏ÄÊò†Â∞Ñ‰∏∫ \"positive\" / \"negative\"\n",
    "    def _map_label(lbl: str) -> str:\n",
    "        L = str(lbl).lower()\n",
    "        if \"pos\" in L or L.endswith(\"1\"):\n",
    "            return \"positive\"\n",
    "        if \"neg\" in L or L.endswith(\"0\"):\n",
    "            return \"negative\"\n",
    "        return \"negative\"\n",
    "\n",
    "    preds_tr = [_map_label(r.get(\"label\", \"\")) for r in raw_preds]\n",
    "\n",
    "    # ËÆ°ÁÆóÂáÜÁ°ÆÁéá\n",
    "    acc_tr = (pd.Series(preds_tr).values == df[\"label\"].values).mean()\n",
    "    print(f\"Samples: {len(df)}\")\n",
    "    print(f\"Accuracy (transformer): {acc_tr:.2%}\")\n",
    "    print(\"First 10 transformer predictions:\")\n",
    "    for t, y, p in list(zip(df[\"text\"], df[\"label\"], preds_tr))[:10]:\n",
    "        print(f\"- {t} | gold={y} | pred={p}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Transformers calibration skipped:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b70152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 ‚Äî Validation\n",
    "import os\n",
    "\n",
    "def _find_sentiment_csv():\n",
    "    for p in [\"./data/sentiment.csv\", \"./sentiment.csv\", \"/mnt/data/sentiment.csv\"]:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "csv_path = _find_sentiment_csv()\n",
    "if csv_path is None:\n",
    "    print(\"‚ùå Could not find 'sentiment.csv'. Place it under ./data/ or alongside this notebook.\")\n",
    "else:\n",
    "    df = load_sentiment_csv(csv_path)\n",
    "    if not {\"text\",\"label\"}.issubset(df.columns):\n",
    "        print(\"‚ùå CSV must contain columns: ['text','label']. Found:\", list(df.columns))\n",
    "    else:\n",
    "        allowed = {\"positive\",\"negative\"}\n",
    "        preds = predict_sentiment_batch(df[\"text\"].tolist())\n",
    "        if any(p not in allowed for p in preds):\n",
    "            bad = {p for p in preds if p not in allowed}\n",
    "            print(\"‚ö†Ô∏è Found unexpected labels in predictions:\", bad)\n",
    "        acc = (pd.Series(preds).values == df[\"label\"].values).mean()\n",
    "        print(f\"Samples: {len(df)}\")\n",
    "        print(f\"Accuracy (rule-based): {acc:.2%}\")\n",
    "        print(\"First 10 predictions:\")\n",
    "        for i, (t, y, p) in enumerate(zip(df[\"text\"].tolist(), df[\"label\"].tolist(), preds)):\n",
    "            if i >= 10: break\n",
    "            print(f\"- {t} | gold={y} | pred={p}\")\n",
    "        if 0 <= acc <= 1:\n",
    "            print(\"‚úÖ Part 3 validation executed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26258ee9",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2 ‚Äî Tiny Retrieval over Doctors CSV\n",
    "\n",
    "**Task**\n",
    "Implement filters over the provided **`doctors.csv`** dataset.\n",
    "\n",
    "**Input**\n",
    "A CSV file **`doctors.csv`** with columns (example):\n",
    "- `id` (int), `name` (str), `specialty` (str), `city` (str), `rating` (float), `notes` (str)\n",
    "\n",
    "**Requirements**\n",
    "1. Implement `load_doctors_csv(path: str = \"./data/doctors.csv\") -> pd.DataFrame` to load the dataset.\n",
    "2. Implement a function `filter_doctors(df: pd.DataFrame, field: str, value: str) -> pd.DataFrame` that returns a **new DataFrame** of rows where `row[field] == value`.\n",
    "   - If the column is string-like, matching should be **case-insensitive**.\n",
    "   - If the column is numeric (e.g., `rating`), interpret `value` as a number and apply exact equality.\n",
    "3. Skip rows missing the requested field (or treat as non-match).\n",
    "4. Do not mutate the input DataFrame. Return a **new** DataFrame.\n",
    "5. Sort the returned DataFrame by `id` ascending.\n",
    "\n",
    "**Notes**\n",
    "- You may assume valid `field` names (but robust handling is encouraged).\n",
    "- For real systems you might support ranges or partial matches; here we keep equality for simplicity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bcd8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Part 4 ‚Äî Code Skeleton\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_doctors_csv(path: str = \"./data/doctors.csv\") -> pd.DataFrame:\n",
    "    \"\"\"Load doctors.csv and return a DataFrame.\"\"\"\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def filter_doctors(df: pd.DataFrame, field: str, value: str) -> pd.DataFrame:\n",
    "    \"\"\"Return a new DataFrame of rows where row[field] == value.\n",
    "    - Case-insensitive for string columns\n",
    "    - Numeric equality for numeric columns\n",
    "    - Sorted by id ascending\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Part 4 ‚Äî Validation\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _find_doctors_csv():\n",
    "    candidates = [\"./data/doctors.csv\", \"./doctors.csv\", \"/mnt/data/doctors.csv\"]\n",
    "    for p in candidates:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def _safe_lower(x):\n",
    "    try:\n",
    "        return str(x).lower()\n",
    "    except Exception:\n",
    "        return x\n",
    "\n",
    "csv_path = _find_doctors_csv()\n",
    "if csv_path is None:\n",
    "    print(\"‚ùå Could not find 'doctors.csv'. Place it under ./data/ or alongside this notebook.\")\n",
    "else:\n",
    "    doctors = load_doctors_csv(csv_path)\n",
    "    expected_cols = {\"id\",\"name\",\"specialty\",\"city\",\"rating\",\"notes\"}\n",
    "    if not expected_cols.issubset(doctors.columns):\n",
    "        print(\"‚ö†Ô∏è Columns differ from expected; proceeding with available columns:\", list(doctors.columns))\n",
    "\n",
    "    try:\n",
    "        derm = filter_doctors(doctors, \"specialty\", \"dermatology\")\n",
    "        city_toronto = filter_doctors(doctors, \"city\", \"toronto\")\n",
    "        name_lee = filter_doctors(doctors, \"name\", \"dr. lee\")\n",
    "        rating_46 = filter_doctors(doctors, \"rating\", \"4.6\")\n",
    "\n",
    "        expected_derm = doctors[doctors[\"specialty\"].map(_safe_lower) == \"dermatology\"].copy().sort_values(\"id\")\n",
    "        expected_toronto = doctors[doctors[\"city\"].map(_safe_lower) == \"toronto\"].copy().sort_values(\"id\")\n",
    "        expected_name = doctors[doctors[\"name\"].map(_safe_lower) == \"dr. lee\"].copy().sort_values(\"id\")\n",
    "        expected_rating = doctors[np.isclose(doctors[\"rating\"].astype(float), 4.6)].copy().sort_values(\"id\")\n",
    "\n",
    "        print(\"specialty == 'dermatology' ->\")\n",
    "        print(derm)\n",
    "        print(\"\\ncity == 'toronto' ->\")\n",
    "        print(city_toronto)\n",
    "        print(\"\\nname == 'dr. lee' ->\")\n",
    "        print(name_lee)\n",
    "        print(\"\\nrating == 4.6 ->\")\n",
    "        print(rating_46)\n",
    "\n",
    "        score = 0\n",
    "        score += int(derm.reset_index(drop=True).equals(expected_derm.reset_index(drop=True)))\n",
    "        score += int(city_toronto.reset_index(drop=True).equals(expected_toronto.reset_index(drop=True)))\n",
    "        score += int(name_lee.reset_index(drop=True).equals(expected_name.reset_index(drop=True)))\n",
    "        score += int(rating_46.reset_index(drop=True).equals(expected_rating.reset_index(drop=True)))\n",
    "\n",
    "        print(f\"\\nScore: {score}/4\")\n",
    "        if score == 4:\n",
    "            print(\"‚úÖ Part 4 validation passed.\")\n",
    "        else:\n",
    "            print(\"‚ÑπÔ∏è Part 4 validation did not pass all checks. Review case-insensitive/string vs numeric equality and sorting.\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Validation raised:\", repr(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview-env-frank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
