{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ff383a",
   "metadata": {},
   "source": [
    "## Question 1 — NLP Mini Practical (Sentiment, CSV)\n",
    "\n",
    "**Scenario**  \n",
    "Your team needs to implement a minimal **sentiment analysis module**.  \n",
    "Given an English sentence, output whether the sentiment is **`positive`** or **`negative`**.\n",
    "\n",
    "---\n",
    "\n",
    "**Input**  \n",
    "CSV file **`sentiment.csv`** with the following columns:\n",
    "\n",
    "- `text` — an English sentence  \n",
    "- `label` — one of `positive` or `negative` (ground truth)\n",
    "\n",
    "---\n",
    "\n",
    "**What to Build**\n",
    "\n",
    "1. `load_sentiment_csv(path: str = \"./data/sentiment.csv\") -> pd.DataFrame`  \n",
    "2. `predict_sentiment(text: str) -> str` → returns **exactly** `\"positive\"` or `\"negative\"`  \n",
    "3. `predict_sentiment_batch(texts: list[str]) -> list[str]`  \n",
    "\n",
    "---\n",
    "\n",
    "**Baseline Requirements (Rule-Based)**\n",
    "\n",
    "- Handle **case-insensitivity**.  \n",
    "- Ignore **punctuation** (reasonable tokenization is acceptable).  \n",
    "- Use **lexicon-based rules** as a starting point.  \n",
    "\n",
    "We provide a very small **sample lexicon** below.  \n",
    "👉 You should **expand it** (add synonyms and common variants to improve accuracy).\n",
    "\n",
    "- `POSITIVE_WORDS` (sample): `{\"good\", \"great\", \"excellent\"}`  \n",
    "- `NEGATIVE_WORDS` (sample): `{\"bad\", \"terrible\", \"awful\"}`  \n",
    "- `NEGATIONS` (sample): `{\"not\", \"no\", \"never\", \"n't\"}`  \n",
    "  *(can be used for polarity flipping, e.g., “not good” → negative)*  \n",
    "\n",
    "---\n",
    "\n",
    "**Optional (Stretch Goal): Transformer Calibration**\n",
    "\n",
    "- If your environment allows (e.g., internet access and `transformers` installed),  \n",
    "  you may additionally run an off-the-shelf model:  \n",
    "  ```python\n",
    "  from transformers import pipeline\n",
    "  sentiment_model = pipeline(\"sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2fedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Part 3 — Candidate Implementation Area ===\n",
    "from typing import List\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# --- SAMPLE LEXICONS (expand these) ---\n",
    "POSITIVE_WORDS = {\"good\", \"great\", \"excellent\"}       # expand\n",
    "NEGATIVE_WORDS = {\"bad\", \"terrible\", \"awful\"}         # expand\n",
    "NEGATIONS = {\"not\", \"no\", \"never\", \"n't\"}             # expand if you handle negation\n",
    "\n",
    "# --- Tokenization (you may replace with your own) ---\n",
    "TOKEN_RE = re.compile(r\"[a-z']+\")\n",
    "\n",
    "def load_sentiment_csv(path: str = \"./data/sentiment.csv\") -> pd.DataFrame:\n",
    "    \"\"\"Load sentiment.csv and return a DataFrame with columns ['text','label'].\"\"\" \n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def predict_sentiment(text: str) -> str:\n",
    "    \"\"\"Return 'positive' or 'negative' (rule-based).\n",
    "    - Case-insensitive\n",
    "    - Ignore punctuation (tokenization)\n",
    "    - (Optional) Handle negation flipping, e.g., 'not good' -> negative\n",
    "    \"\"\"\n",
    "    # TODO: implement your rule-based classifier\n",
    "    # Hints (not required): lowercase, tokenize, count pos/neg hits, optional negation flip\n",
    "    raise NotImplementedError\n",
    "\n",
    "def predict_sentiment_batch(texts: List[str]) -> List[str]:\n",
    "    \"\"\"Vectorized helper that applies predict_sentiment to a list of texts.\"\"\"\n",
    "    return [predict_sentiment(t) for t in texts]\n",
    "\n",
    "# --- Optional: Transformer path (define ONLY if you choose to use HF pipeline) ---\n",
    "def predict_sentiment_transformer_batch(texts: List[str]) -> List[str]:\n",
    "    \"\"\"(Optional) Return predictions via a pretrained transformer as 'positive'/'negative'.\n",
    "    If you do not implement this, keep it raising NotImplementedError.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b70152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Part 3 — Validation (supports both rule-based & optional transformer) ===\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def _find_sentiment_csv():\n",
    "    for p in [\"./data/sentiment.csv\", \"./sentiment.csv\", \"/mnt/data/sentiment.csv\"]:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def _validate_preds(name: str, gold: pd.Series, preds: list):\n",
    "    allowed = {\"positive\",\"negative\"}\n",
    "    if any(p not in allowed for p in preds):\n",
    "        bad = {p for p in preds if p not in allowed}\n",
    "        print(f\"⚠️ [{name}] Found unexpected labels:\", bad)\n",
    "    acc = (pd.Series(preds).values == gold.values).mean()\n",
    "    print(f\"Accuracy ({name}): {acc:.2%}\")\n",
    "    print(f\"First 10 predictions ({name}):\")\n",
    "    for t, y, p in list(zip(df[\"text\"], df[\"label\"], preds))[:10]:\n",
    "        print(f\"- {t} | gold={y} | pred={p}\")\n",
    "    return acc\n",
    "\n",
    "csv_path = _find_sentiment_csv()\n",
    "if csv_path is None:\n",
    "    print(\"❌ Could not find 'sentiment.csv'. Place it under ./data/ or alongside this notebook.\")\n",
    "else:\n",
    "    df = load_sentiment_csv(csv_path)\n",
    "    if not {\"text\",\"label\"}.issubset(df.columns):\n",
    "        print(\"❌ CSV must contain columns: ['text','label']. Found:\", list(df.columns))\n",
    "    else:\n",
    "        print(f\"Samples: {len(df)}\")\n",
    "\n",
    "        # 1) Rule-based (required)\n",
    "        try:\n",
    "            preds_rule = predict_sentiment_batch(df[\"text\"].tolist())\n",
    "            acc_rule = _validate_preds(\"rule-based\", df[\"label\"], preds_rule)\n",
    "        except NotImplementedError:\n",
    "            print(\"❌ Rule-based path not implemented (predict_sentiment raises NotImplementedError).\")\n",
    "            acc_rule = None\n",
    "        except Exception as e:\n",
    "            print(\"❌ Rule-based validation raised:\", repr(e))\n",
    "            acc_rule = None\n",
    "\n",
    "        # 2) Optional transformer (only if implemented by candidate)\n",
    "        acc_tr = None\n",
    "        if \"predict_sentiment_transformer_batch\" in globals():\n",
    "            try:\n",
    "                preds_tr = predict_sentiment_transformer_batch(df[\"text\"].tolist())\n",
    "                acc_tr = _validate_preds(\"transformer\", df[\"label\"], preds_tr)\n",
    "            except NotImplementedError:\n",
    "                print(\"ℹ️ Transformer path not implemented (skipped).\")\n",
    "            except Exception as e:\n",
    "                print(\"⚠️ Transformer validation skipped due to error:\", repr(e))\n",
    "        else:\n",
    "            print(\"ℹ️ No transformer hook found (predict_sentiment_transformer_batch). Skipping.\")\n",
    "\n",
    "        # Summary\n",
    "        print(\"\\n=== Summary ===\")\n",
    "        print(\"Rule-based accuracy:\", \"N/A\" if acc_rule is None else f\"{acc_rule:.2%}\")\n",
    "        print(\"Transformer accuracy:\", \"N/A\" if acc_tr is None else f\"{acc_tr:.2%}\")\n",
    "        print(\"✅ Part 3 validation executed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26258ee9",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2 — Tiny Retrieval over Doctors CSV\n",
    "\n",
    "**Task**\n",
    "Implement filters over the provided **`doctors.csv`** dataset.\n",
    "\n",
    "**Input**\n",
    "A CSV file **`doctors.csv`** with columns (example):\n",
    "- `id` (int), `name` (str), `specialty` (str), `city` (str), `rating` (float), `notes` (str)\n",
    "\n",
    "**Requirements**\n",
    "1. Implement `load_doctors_csv(path: str = \"./data/doctors.csv\") -> pd.DataFrame` to load the dataset.\n",
    "2. Implement a function `filter_doctors(df: pd.DataFrame, field: str, value: str) -> pd.DataFrame` that returns a **new DataFrame** of rows where `row[field] == value`.\n",
    "   - If the column is string-like, matching should be **case-insensitive**.\n",
    "   - If the column is numeric (e.g., `rating`), interpret `value` as a number and apply exact equality.\n",
    "3. Skip rows missing the requested field (or treat as non-match).\n",
    "4. Do not mutate the input DataFrame. Return a **new** DataFrame.\n",
    "5. Sort the returned DataFrame by `id` ascending.\n",
    "\n",
    "**Notes**\n",
    "- You may assume valid `field` names (but robust handling is encouraged).\n",
    "- For real systems you might support ranges or partial matches; here we keep equality for simplicity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bcd8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Part 4 — Code Skeleton\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_doctors_csv(path: str = \"./data/doctors.csv\") -> pd.DataFrame:\n",
    "    \"\"\"Load doctors.csv and return a DataFrame.\"\"\"\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def filter_doctors(df: pd.DataFrame, field: str, value: str) -> pd.DataFrame:\n",
    "    \"\"\"Return a new DataFrame of rows where row[field] == value.\n",
    "    - Case-insensitive for string columns\n",
    "    - Numeric equality for numeric columns\n",
    "    - Sorted by id ascending\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Part 4 — Validation\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def _find_doctors_csv():\n",
    "    candidates = [\"./data/doctors.csv\", \"./doctors.csv\", \"/mnt/data/doctors.csv\"]\n",
    "    for p in candidates:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def _safe_lower(x):\n",
    "    try:\n",
    "        return str(x).lower()\n",
    "    except Exception:\n",
    "        return x\n",
    "\n",
    "csv_path = _find_doctors_csv()\n",
    "if csv_path is None:\n",
    "    print(\"❌ Could not find 'doctors.csv'. Place it under ./data/ or alongside this notebook.\")\n",
    "else:\n",
    "    doctors = load_doctors_csv(csv_path)\n",
    "    expected_cols = {\"id\",\"name\",\"specialty\",\"city\",\"rating\",\"notes\"}\n",
    "    if not expected_cols.issubset(doctors.columns):\n",
    "        print(\"⚠️ Columns differ from expected; proceeding with available columns:\", list(doctors.columns))\n",
    "\n",
    "    try:\n",
    "        derm = filter_doctors(doctors, \"specialty\", \"dermatology\")\n",
    "        city_toronto = filter_doctors(doctors, \"city\", \"toronto\")\n",
    "        name_lee = filter_doctors(doctors, \"name\", \"dr. lee\")\n",
    "        rating_46 = filter_doctors(doctors, \"rating\", \"4.6\")\n",
    "\n",
    "        expected_derm = doctors[doctors[\"specialty\"].map(_safe_lower) == \"dermatology\"].copy().sort_values(\"id\")\n",
    "        expected_toronto = doctors[doctors[\"city\"].map(_safe_lower) == \"toronto\"].copy().sort_values(\"id\")\n",
    "        expected_name = doctors[doctors[\"name\"].map(_safe_lower) == \"dr. lee\"].copy().sort_values(\"id\")\n",
    "        expected_rating = doctors[np.isclose(doctors[\"rating\"].astype(float), 4.6)].copy().sort_values(\"id\")\n",
    "\n",
    "        print(\"specialty == 'dermatology' ->\")\n",
    "        print(derm)\n",
    "        print(\"\\ncity == 'toronto' ->\")\n",
    "        print(city_toronto)\n",
    "        print(\"\\nname == 'dr. lee' ->\")\n",
    "        print(name_lee)\n",
    "        print(\"\\nrating == 4.6 ->\")\n",
    "        print(rating_46)\n",
    "\n",
    "        score = 0\n",
    "        score += int(derm.reset_index(drop=True).equals(expected_derm.reset_index(drop=True)))\n",
    "        score += int(city_toronto.reset_index(drop=True).equals(expected_toronto.reset_index(drop=True)))\n",
    "        score += int(name_lee.reset_index(drop=True).equals(expected_name.reset_index(drop=True)))\n",
    "        score += int(rating_46.reset_index(drop=True).equals(expected_rating.reset_index(drop=True)))\n",
    "\n",
    "        print(f\"\\nScore: {score}/4\")\n",
    "        if score == 4:\n",
    "            print(\"✅ Part 4 validation passed.\")\n",
    "        else:\n",
    "            print(\"ℹ️ Part 4 validation did not pass all checks. Review case-insensitive/string vs numeric equality and sorting.\")\n",
    "    except Exception as e:\n",
    "        print(\"❌ Validation raised:\", repr(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interview-env-frank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
